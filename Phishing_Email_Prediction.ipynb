{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNl7GVtCxOYhqxbE5/OD2HE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anna-asmaryan/NSBE-Hacks/blob/email_phishing/Phishing_Email_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "\n",
        "import urllib.request\n",
        "import joblib\n",
        "\n",
        "# GitHub raw file URLs\n",
        "vectorizer_url = \"https://github.com/anna-asmaryan/NSBE-Hacks/raw/refs/heads/email_phishing/vectorizer.pkl\"\n",
        "model_url = \"https://github.com/anna-asmaryan/NSBE-Hacks/raw/refs/heads/email_phishing/logistic_model.pkl\"\n",
        "\n",
        "# Download the files\n",
        "urllib.request.urlretrieve(vectorizer_url, \"vectorizer.pkl\")\n",
        "urllib.request.urlretrieve(model_url, \"logistic_model.pkl\")\n",
        "\n",
        "# Load the vectorizer and model\n",
        "vectorizer = joblib.load(\"vectorizer.pkl\")\n",
        "model = joblib.load(\"logistic_model.pkl\")\n",
        "\n",
        "import numpy as np\n",
        "import joblib\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "from string import punctuation\n",
        "\n",
        "\n",
        "# Initialize NLP tools\n",
        "nltk.download('punkt', quiet=True)       # For tokenization\n",
        "nltk.download('stopwords', quiet=True)   # For stopwords\n",
        "nltk.download('wordnet', quiet=True)     # For lemmatization\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "# Function to process the email body and predict if email is spam\n",
        "def check_if_phishing(body):\n",
        "    tokens = word_tokenize(body)\n",
        "    stop_words = set(stopwords.words('english')) | set(punctuation)\n",
        "\n",
        "    processed_tokens = [\n",
        "        stemmer.stem(lemmatizer.lemmatize(word.lower()))\n",
        "        for word in tokens\n",
        "        if word.lower() not in stop_words\n",
        "    ]\n",
        "    processed_body = ' '.join(processed_tokens)  # Process text\n",
        "\n",
        "    #STEP 2: Vectorized the processed body\n",
        "    email_vec = vectorizer.transform([processed_body])\n",
        "\n",
        "    #STEP 3: Determine the prediction\n",
        "    prediction = model.predict(email_vec)[0]\n",
        "    return prediction\n",
        "    #If predictions = 1, the email is a phishing email. If 0, it is legitimate.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4TaU1Jbqh7I_"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}