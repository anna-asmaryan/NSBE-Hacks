{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNJsdmfhB44G9O8bb6orifl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anna-asmaryan/NSBE-Hacks/blob/email_phishing/NSBE_Hacks_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import needed libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter"
      ],
      "metadata": {
        "id": "CYcqmnaCOwLk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7byK3nnDq_I",
        "outputId": "7cf29323-6a30-4604-f469-e9e09bc7396c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.8).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.8).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.8).\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.8).\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies as needed:\n",
        "# pip install kagglehub[pandas-datasets]\n",
        "\n",
        "# Set the path to the files you'd like to load\n",
        "file_paths = [\"CEAS_08.csv\", \"Nazario.csv\", \"Nigerian_Fraud.csv\", \"SpamAssasin.csv\"]\n",
        "\n",
        "# Create empty dataframe with sender email, reciever, subject, body, and label\n",
        "df = pd.DataFrame(columns=[\"sender\", \"receiver\", \"date\", \"subject\", \"body\", \"urls\", \"label\"])\n",
        "\n",
        "# Load the latest version\n",
        "for file_path in file_paths:\n",
        "  df_temp = kagglehub.load_dataset(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    \"naserabdullahalam/phishing-email-dataset\",\n",
        "    file_path,\n",
        "    # Provide any additional arguments like\n",
        "    # sql_query or pandas_kwargs. See the\n",
        "    # documenation for more information:\n",
        "    # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
        "  )\n",
        "  df_temp = df_temp.loc[:, [\"sender\", \"receiver\", \"date\", \"subject\", \"body\", \"urls\", \"label\"]]\n",
        "\n",
        "  df = pd.concat([df, df_temp])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning the dataset"
      ],
      "metadata": {
        "id": "L3c1xvpWK0GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dimentions of dataset\n",
        "print(\"First 5 records:\\n\", df.head(), \"\\n\")\n",
        "print(\"Dimensions:\\n\", df.shape, \"\\n\")\n",
        "\n",
        "# Check variables summaries\n",
        "print(\"Variables:\\n\", df.describe(), \"\\n\")\n",
        "print(\"Variables types:\\n\", df.dtypes, \"\\n\")\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values:\\n\", df.isnull().sum(), \"\\n\")"
      ],
      "metadata": {
        "id": "hL5E266sKrWC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34187007-a3b3-422c-ffeb-fe9eae758b76"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 records:\n",
            "                                               sender  \\\n",
            "0                   Young Esposito <Young@iworld.de>   \n",
            "1                       Mok <ipline's1983@icable.ph>   \n",
            "2  Daily Top 10 <Karmandeep-opengevl@universalnet...   \n",
            "3                 Michael Parker <ivqrnai@pobox.com>   \n",
            "4  Gretchen Suggs <externalsep1@loanofficertool.com>   \n",
            "\n",
            "                                         receiver  \\\n",
            "0                     user4@gvc.ceas-challenge.cc   \n",
            "1                   user2.2@gvc.ceas-challenge.cc   \n",
            "2                   user2.9@gvc.ceas-challenge.cc   \n",
            "3  SpamAssassin Dev <xrh@spamassassin.apache.org>   \n",
            "4                   user2.2@gvc.ceas-challenge.cc   \n",
            "\n",
            "                              date  \\\n",
            "0  Tue, 05 Aug 2008 16:31:02 -0700   \n",
            "1  Tue, 05 Aug 2008 18:31:03 -0500   \n",
            "2  Tue, 05 Aug 2008 20:28:00 -1200   \n",
            "3  Tue, 05 Aug 2008 17:31:20 -0600   \n",
            "4  Tue, 05 Aug 2008 19:31:21 -0400   \n",
            "\n",
            "                                             subject  \\\n",
            "0                          Never agree to be a loser   \n",
            "1                             Befriend Jenna Jameson   \n",
            "2                               CNN.com Daily Top 10   \n",
            "3  Re: svn commit: r619753 - in /spamassassin/tru...   \n",
            "4                         SpecialPricesPharmMoreinfo   \n",
            "\n",
            "                                                body urls label  \n",
            "0  Buck up, your troubles caused by small dimensi...    1     1  \n",
            "1  \\nUpgrade your sex and pleasures with these te...    1     1  \n",
            "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...    1     1  \n",
            "3  Would anyone object to removing .so from this ...    1     0  \n",
            "4  \\nWelcomeFastShippingCustomerSupport\\nhttp://7...    1     1   \n",
            "\n",
            "Dimensions:\n",
            " (49860, 7) \n",
            "\n",
            "Variables:\n",
            "                                    sender                     receiver  \\\n",
            "count                               49529                        47768   \n",
            "unique                              31415                         6510   \n",
            "top     qydlqcws-iacfym@issues.apache.org  user6@gvc.ceas-challenge.cc   \n",
            "freq                                  462                         1375   \n",
            "\n",
            "                                   date               subject   body   urls  \\\n",
            "count                             49377                 49773  49859  49860   \n",
            "unique                            48622                 23560  49857      2   \n",
            "top     Thu, 07 Aug 2008 21:38:18 -0100  CNN.com Daily Top 10   \\n\\n      1   \n",
            "freq                                  8                  2930      3  33806   \n",
            "\n",
            "        label  \n",
            "count   49860  \n",
            "unique      2  \n",
            "top         1  \n",
            "freq    28457   \n",
            "\n",
            "Variables types:\n",
            " sender      object\n",
            "receiver    object\n",
            "date        object\n",
            "subject     object\n",
            "body        object\n",
            "urls        object\n",
            "label       object\n",
            "dtype: object \n",
            "\n",
            "Missing values:\n",
            " sender       331\n",
            "receiver    2092\n",
            "date         483\n",
            "subject       87\n",
            "body           1\n",
            "urls           0\n",
            "label          0\n",
            "dtype: int64 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop na values in body column\n",
        "df = df.dropna(subset=['body'])\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values:\\n\", df.isnull().sum(), \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wXeLr90OJ2i",
        "outputId": "0cdc8309-4278-49a5-ccea-fe8a550bff3e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values:\n",
            " sender       331\n",
            "receiver    2092\n",
            "date         483\n",
            "subject       87\n",
            "body           0\n",
            "urls           0\n",
            "label          0\n",
            "dtype: int64 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Begin vectorizing body data"
      ],
      "metadata": {
        "id": "LbVQHLIgOj1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the body\n",
        "df['vector body'] = df['body'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Remove stop words\n",
        "stopset = set(stopwords.words('english'))\n",
        "df['vector body'] = df['vector body'].apply(lambda x: [word for word in x if word not in stopset])\n",
        "\n",
        "# Lemmatizing the body\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['vector body'] = df['vector body'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
        "\n",
        "# Stemming the body\n",
        "stemmer = PorterStemmer()\n",
        "df['vector body'] = df['vector body'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
        "\n",
        "# Join tokens back into a string\n",
        "df['vector body'] = df['vector body'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Vectorize the body with Count adn Tfidf vector versions\n",
        "cv = CountVectorizer()\n",
        "cv_matrix = cv.fit_transform(df['vector body'])\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(df['vector body'])"
      ],
      "metadata": {
        "id": "bkk8V8QhOi_D"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting to training, validating, and testing split\n",
        "X_train, X_test_val, y_train, y_test_val = train_test_split(tfidf_matrix, df['label'], test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, test_size=0.25, random_state=42)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"X_test shape:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2-IWoIxVuiq",
        "outputId": "43c88148-fa41-4ccb-d281-fdb026929f8c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (29915, 412442)\n",
            "X_val shape: (14958, 412442)\n",
            "X_test shape: (4986, 412442)\n"
          ]
        }
      ]
    }
  ]
}