{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlbt08yziJb45PefIFBW33",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anna-asmaryan/NSBE-Hacks/blob/email_phishing/NSBE_Hacks_2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import needed libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.stem import PorterStemmer\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter"
      ],
      "metadata": {
        "id": "CYcqmnaCOwLk"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#nltk.download('punkt_tab')\n",
        "#nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DCm_--lzwHdi",
        "outputId": "c04da3cf-49e7-4f36-8d88-6c1d4f5f721e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7byK3nnDq_I",
        "outputId": "981f8942-71d2-4e5f-81c7-595422f28b87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.8).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/naserabdullahalam/phishing-email-dataset?dataset_version_number=1&file_name=CEAS_08.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19.0M/19.0M [00:00<00:00, 44.3MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting zip of CEAS_08.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.8).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/naserabdullahalam/phishing-email-dataset?dataset_version_number=1&file_name=Nazario.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.24M/3.24M [00:00<00:00, 128MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting zip of Nazario.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.8).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/naserabdullahalam/phishing-email-dataset?dataset_version_number=1&file_name=Nigerian_Fraud.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.01M/3.01M [00:00<00:00, 106MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting zip of Nigerian_Fraud.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.7), please consider upgrading to the latest version (0.3.8).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/naserabdullahalam/phishing-email-dataset?dataset_version_number=1&file_name=SpamAssasin.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.91M/4.91M [00:00<00:00, 64.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting zip of SpamAssasin.csv...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Install dependencies as needed:\n",
        "# pip install kagglehub[pandas-datasets]\n",
        "\n",
        "# Set the path to the files you'd like to load\n",
        "file_paths = [\"CEAS_08.csv\", \"Nazario.csv\", \"Nigerian_Fraud.csv\", \"SpamAssasin.csv\"]\n",
        "\n",
        "# Create empty dataframe with sender email, reciever, subject, body, and label\n",
        "df = pd.DataFrame(columns=[\"sender\", \"receiver\", \"date\", \"subject\", \"body\", \"urls\", \"label\"])\n",
        "\n",
        "# Load the latest version\n",
        "for file_path in file_paths:\n",
        "  df_temp = kagglehub.load_dataset(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    \"naserabdullahalam/phishing-email-dataset\",\n",
        "    file_path,\n",
        "    # Provide any additional arguments like\n",
        "    # sql_query or pandas_kwargs. See the\n",
        "    # documenation for more information:\n",
        "    # https://github.com/Kaggle/kagglehub/blob/main/README.md#kaggledatasetadapterpandas\n",
        "  )\n",
        "  df_temp = df_temp.loc[:, [\"sender\", \"receiver\", \"date\", \"subject\", \"body\", \"urls\", \"label\"]]\n",
        "\n",
        "  df = pd.concat([df, df_temp])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cleaning the dataset"
      ],
      "metadata": {
        "id": "L3c1xvpWK0GW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check dimentions of dataset\n",
        "print(\"First 5 records:\\n\", df.head(), \"\\n\")\n",
        "print(\"Dimensions:\\n\", df.shape, \"\\n\")\n",
        "\n",
        "# Check variables summaries\n",
        "print(\"Variables:\\n\", df.describe(), \"\\n\")\n",
        "print(\"Variables types:\\n\", df.dtypes, \"\\n\")\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values:\\n\", df.isnull().sum(), \"\\n\")"
      ],
      "metadata": {
        "id": "hL5E266sKrWC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4742dc14-b3c6-4944-d63a-1012bd21e419"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 records:\n",
            "                                               sender  \\\n",
            "0                   Young Esposito <Young@iworld.de>   \n",
            "1                       Mok <ipline's1983@icable.ph>   \n",
            "2  Daily Top 10 <Karmandeep-opengevl@universalnet...   \n",
            "3                 Michael Parker <ivqrnai@pobox.com>   \n",
            "4  Gretchen Suggs <externalsep1@loanofficertool.com>   \n",
            "\n",
            "                                         receiver  \\\n",
            "0                     user4@gvc.ceas-challenge.cc   \n",
            "1                   user2.2@gvc.ceas-challenge.cc   \n",
            "2                   user2.9@gvc.ceas-challenge.cc   \n",
            "3  SpamAssassin Dev <xrh@spamassassin.apache.org>   \n",
            "4                   user2.2@gvc.ceas-challenge.cc   \n",
            "\n",
            "                              date  \\\n",
            "0  Tue, 05 Aug 2008 16:31:02 -0700   \n",
            "1  Tue, 05 Aug 2008 18:31:03 -0500   \n",
            "2  Tue, 05 Aug 2008 20:28:00 -1200   \n",
            "3  Tue, 05 Aug 2008 17:31:20 -0600   \n",
            "4  Tue, 05 Aug 2008 19:31:21 -0400   \n",
            "\n",
            "                                             subject  \\\n",
            "0                          Never agree to be a loser   \n",
            "1                             Befriend Jenna Jameson   \n",
            "2                               CNN.com Daily Top 10   \n",
            "3  Re: svn commit: r619753 - in /spamassassin/tru...   \n",
            "4                         SpecialPricesPharmMoreinfo   \n",
            "\n",
            "                                                body urls label  \n",
            "0  Buck up, your troubles caused by small dimensi...    1     1  \n",
            "1  \\nUpgrade your sex and pleasures with these te...    1     1  \n",
            "2  >+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+=+...    1     1  \n",
            "3  Would anyone object to removing .so from this ...    1     0  \n",
            "4  \\nWelcomeFastShippingCustomerSupport\\nhttp://7...    1     1   \n",
            "\n",
            "Dimensions:\n",
            " (49860, 7) \n",
            "\n",
            "Variables:\n",
            "                                    sender                     receiver  \\\n",
            "count                               49529                        47768   \n",
            "unique                              31415                         6510   \n",
            "top     qydlqcws-iacfym@issues.apache.org  user6@gvc.ceas-challenge.cc   \n",
            "freq                                  462                         1375   \n",
            "\n",
            "                                   date               subject   body   urls  \\\n",
            "count                             49377                 49773  49859  49860   \n",
            "unique                            48622                 23560  49857      2   \n",
            "top     Thu, 07 Aug 2008 21:38:18 -0100  CNN.com Daily Top 10   \\n\\n      1   \n",
            "freq                                  8                  2930      3  33806   \n",
            "\n",
            "        label  \n",
            "count   49860  \n",
            "unique      2  \n",
            "top         1  \n",
            "freq    28457   \n",
            "\n",
            "Variables types:\n",
            " sender      object\n",
            "receiver    object\n",
            "date        object\n",
            "subject     object\n",
            "body        object\n",
            "urls        object\n",
            "label       object\n",
            "dtype: object \n",
            "\n",
            "Missing values:\n",
            " sender       331\n",
            "receiver    2092\n",
            "date         483\n",
            "subject       87\n",
            "body           1\n",
            "urls           0\n",
            "label          0\n",
            "dtype: int64 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop na values in body column\n",
        "df = df.dropna(subset=['body'])\n",
        "\n",
        "# Check for missing values\n",
        "print(\"Missing values:\\n\", df.isnull().sum(), \"\\n\")\n",
        "\n",
        "# Convert parameters to proper types\n",
        "df['sender'] = df['sender'].astype(str)\n",
        "df['receiver'] = df['receiver'].astype(str)\n",
        "df['subject'] = df['subject'].astype(str)\n",
        "df['body'] = df['body'].astype(str)\n",
        "df['urls'] = df['urls'].astype(str)\n",
        "df['label'] = pd.to_numeric(df['label'], errors='coerce').astype(int)\n",
        "\n",
        "print(\"Variables types:\\n\", df.dtypes, \"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wXeLr90OJ2i",
        "outputId": "0312eed4-cb9f-4071-fc99-0059fdd4f798"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Missing values:\n",
            " sender           0\n",
            "receiver         0\n",
            "date           483\n",
            "subject          0\n",
            "body             0\n",
            "urls             0\n",
            "label            0\n",
            "vector body      0\n",
            "dtype: int64 \n",
            "\n",
            "Variables types:\n",
            " sender         object\n",
            "receiver       object\n",
            "date           object\n",
            "subject        object\n",
            "body           object\n",
            "urls           object\n",
            "label           int64\n",
            "vector body    object\n",
            "dtype: object \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Begin vectorizing body data"
      ],
      "metadata": {
        "id": "LbVQHLIgOj1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the body\n",
        "#df['vector body'] = df['body'].apply(lambda x: word_tokenize(x.lower()))\n",
        "\n",
        "# Remove stop words\n",
        "#stopset = set(stopwords.words('english'))\n",
        "#df['vector body'] = df['vector body'].apply(lambda x: [word for word in x if word not in stopset])\n",
        "\n",
        "# Lemmatizing the body\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "df['vector body'] = df['vector body'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
        "\n",
        "# Stemming the body\n",
        "stemmer = PorterStemmer()\n",
        "df['vector body'] = df['vector body'].apply(lambda x: [stemmer.stem(word) for word in x])\n",
        "\n",
        "# Join tokens back into a string\n",
        "df['vector body'] = df['vector body'].apply(lambda x: ' '.join(x))\n",
        "\n",
        "# Vectorize the body with Count adn Tfidf vector versions\n",
        "tfidf = TfidfVectorizer()\n",
        "tfidf_matrix = tfidf.fit_transform(df['vector body'])"
      ],
      "metadata": {
        "id": "bkk8V8QhOi_D"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting to training, validating, and testing split\n",
        "X_train, X_test_val, y_train, y_test_val = train_test_split(tfidf_matrix, df['label'], test_size=0.4, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_test_val, y_test_val, test_size=0.25, random_state=42)\n",
        "\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_val shape:\", X_val.shape)\n",
        "print(\"X_test shape:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2-IWoIxVuiq",
        "outputId": "9e732cb0-b472-478c-e721-7c5c13a16c09"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (29915, 412442)\n",
            "X_val shape: (14958, 412442)\n",
            "X_test shape: (4986, 412442)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing Naive Bayes Model"
      ],
      "metadata": {
        "id": "AH2gFb1Txnj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit traning dataset to naive bayes classifier\n",
        "Naive =  MultinomialNB()\n",
        "Naive.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels on validation dataset\n",
        "predictions_NB = Naive.predict(X_val)\n",
        "predictions_train = Naive.predict(X_train)\n",
        "\n",
        "# Use accuracy_score function to get the accuracy\n",
        "print(\"Naive Bayes Training Accuracy Score ->\", accuracy_score(predictions_train, y_train)*100)\n",
        "print(\"Naive Bayes Validation Accuracy Score -> \", accuracy_score(predictions_NB, y_val)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4KzRU1zxu7t",
        "outputId": "6605d0c6-cfd7-4c04-fc50-4f87b2830669"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes Training Accuracy Score -> 98.83670399465151\n",
            "Naive Bayes Validation Accuracy Score ->  98.07460890493381\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3o5xA7ls6zH8"
      }
    }
  ]
}